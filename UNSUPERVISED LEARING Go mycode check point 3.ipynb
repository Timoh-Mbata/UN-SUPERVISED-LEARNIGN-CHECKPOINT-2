{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "632bd950-9b8d-4374-a957-eaed3331e3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nIn this checkpoint, we are going to work on the 'Credit Card Dataset for Clustering' dataset provided by Kaggle.\\nDataset description : This dataset was derived and simplified for learning purposes. \\nIt includes usage behaviour of about 9000 active credit card holders during 6 months period.\\nThis case requires to develop a customer segmentation to define marketing strategy.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "In this checkpoint, we are going to work on the 'Credit Card Dataset for Clustering' dataset provided by Kaggle.\n",
    "Dataset description : This dataset was derived and simplified for learning purposes. \n",
    "It includes usage behaviour of about 9000 active credit card holders during 6 months period.\n",
    "This case requires to develop a customer segmentation to define marketing strategy.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "282922c6-db64-4e1f-98d7-2b5ae83e92b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cbf5758-c5b9-4a4e-b827-9f97d70cccc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Credit_card_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCredit_card_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Credit_card_dataset.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Credit_card_dataset.csv')\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea2c96b-9b07-4f70-8e91-ad7867f99dab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# UNDERSTANDING MY DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c0ff39-e38f-4a8a-bacc-f7ed82a541c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b503c19-ee0c-426c-b5e9-8c85901f8d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030957a-b891-4b2e-8189-9be94a376781",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6274c9a9-be11-41d8-a7cf-0364fbb57680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c528892d-54f5-4445-aa03-43da75bb6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21ceea-b92a-4380-a73a-a0532ded4ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ea2b4-8065-455a-bce2-c1b670619ecc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b520a8-33a4-4fc1-ad2a-cb9aadca36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81982d5-92a0-4a11-9b5d-120dab0bdc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIVARIETE ANALYSIS\n",
    "plt.hist(data['CREDIT_LIMIT'],bins=50)\n",
    "plt.xlabel(\"CREDIT_LIMIT FREQUENCY\")\n",
    "plt.ylabel(\"FREQUENCY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed014d-93f1-4d02-aacb-1a35cf0dbe14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BIVARIATE ANALYSIS\n",
    "plt.scatter(data['CREDIT_LIMIT'][:50],data.PURCHASES[:50],marker=\"o\",color=\"green\",label = \"purchases\")\n",
    "plt.xlabel(\"PURCHASES\")\n",
    "plt.ylabel(\"CREDIT_LIMIT\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a1d1b9-00f7-49c3-9a7c-1c186c20aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(data['CREDIT_LIMIT'][:50],data.PURCHASES[:50],marker=\"o\",color=\"green\",label = \"purchases\")\n",
    "plt.scatter(data['CREDIT_LIMIT'][:100],data.PAYMENTS[:100],marker=\"o\",color=\"r\",label=\"PAYMENTS\")\n",
    "# plt.scatter(data['BALANCE_FREQUENCY'],data.CREDIT_LIMIT,marker=\"o\",color=\"blue\")\n",
    "plt.xlabel(\"PAYMENTS\")\n",
    "plt.ylabel(\"CREDIT_LIMIT\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8e923b-422b-437a-adc0-731f772d399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['CREDIT_LIMIT'][:100],data.CASH_ADVANCE[:100],marker=\"o\",color=\"blue\",label=\"Cash in Advance\")\n",
    "plt.xlabel(\"PURCHASES\")\n",
    "plt.ylabel(\"CREDIT_LIMIT\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95697cf4-8450-4167-ac5e-82437d78fe47",
   "metadata": {},
   "source": [
    " # REMARKS FROM THE ANALYSIS \n",
    "'''from the 1.univariate analysis (single feature analysis) . You can tell that alot of customers have low credit limts of below 5000 while few of them have high credit limits above 2000 . This Aids in Marketing It apears that alot of our clients want low amounts of loan below 5000 so to achieve the high customer retention we should :\n",
    "Digital Engagement: Utilize digital platforms to offer convenient loan applications and management. \n",
    "Engage customers through mobile apps, SMS, and social media to keep them informed about new offers and their loan status.\n",
    "\n",
    "\n",
    "2.From the bivariete analysis we can litary see that there are Classters in the way our customers bahave .\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b02a4e-a3be-4b56-a8d5-5cfc7a6ca8a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# FEATURE ENGINEERING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15922220-199c-4787-b769-8f1ef190a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CLEANING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1c3dc-a974-4c2d-9fd1-7c908be43fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482db3c-4df8-4b60-a783-48101d14f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37532166-0690-46f7-827d-ae6b15efeb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna() # droping the empty cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f3258-a051-4b0c-9666-e67a8e0262bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CUST_ID'].duplicated().sum() # checking for the duplicated columns in my dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf556d-5ff7-421c-ba7d-bcea931864d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers in the data set\n",
    "# BALANCE_FREQUENCY: How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n",
    "# check for outliers in the credit card limit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e0040-68f2-4de7-bdd2-9b43be4bfd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_gretaer_1 = data[data['BALANCE_FREQUENCY']>1] # get the values that are greter than 1 in the column\n",
    "len(frequency_gretaer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f6f473-1b5d-40b2-be7f-5bb4909c4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = data['CREDIT_LIMIT'].quantile(0.25)\n",
    "q3 = data['CREDIT_LIMIT'].quantile(0.75)\n",
    "\n",
    "IQR = q3-q1\n",
    "print (f\"the q1 is {q1}\")\n",
    "print (f\"the q2 is {q3}\")\n",
    "print (f\"the IQR is {IQR}\")\n",
    "\n",
    "lower_limit = q1-1.5*(IQR)\n",
    "upper_limit = q3+1.5 * (IQR)\n",
    "\n",
    "print (f\"the lower limit is {lower_limit}\")\n",
    "print (f\"the upper limit  is {upper_limit}\")\n",
    "outliers = data[(data[\"CREDIT_LIMIT\"]<lower_limit) | (data[\"CREDIT_LIMIT\"]>upper_limit)]\n",
    "print (f\"the number of outliers is {len(outliers)}\")\n",
    "filtered_data = data[(data[\"CREDIT_LIMIT\"]>= lower_limit) & (data[\"CREDIT_LIMIT\"] <= upper_limit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82685a-d81d-4057-ada1-bd9883764340",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fad5ea-26bd-4562-b3a9-2ae51edb39c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = filtered_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e016c3b-64ad-4a80-94d2-e180276ef5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FETURE SELECTION \n",
    "from sklearn.model_selection import train_test_split\n",
    "# xtrain,xtest,ytain,ytest = train_test_split()\n",
    "from sklearn.feature_selection import VarianceThreshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194b2d7-b9ff-42ad-8751-55d9efd72099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def varience(dataset,threshold):\n",
    "    get_variance = VarianceThreshold(threshold=threshold)\n",
    "    get_variance.fit(dataset)\n",
    "    return pd.Series(get_variance.get_support(),index=dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77aecc3-1def-42cb-9d38-3948d2fb0c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "varience(data2.drop(columns=['CUST_ID']),0.1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10ccbb30-d2cd-49d2-a5a0-1a00b9313159",
   "metadata": {},
   "source": [
    "You realise that the Balance Frequency column has the frequency of lower than 0.1 of which its true beacuse the values are between 0 and 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124bcc50-8fc4-43f0-8ab9-44e621fdb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.BALANCE_FREQUENCY[:5] # BALANCE_FREQUENCY: How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f2efa-7968-423d-92e5-5552f253969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highly correwlated features in my dataset can imply the same thing especialy when its posituve correlation ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a20fe-9f9f-40b6-8d95-0fba2293d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.title(\"CORRELATIONS\")\n",
    "sns.heatmap(data2.select_dtypes(exclude='object').corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798db21d-3943-4a6b-9958-942b1fb2a509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a14bc620-0bbb-4170-89ff-2f69f26c25a2",
   "metadata": {},
   "source": [
    "# CLUSTERING ALGORITHMS TO GET THE DIFFERENT CLUSTERS LABELS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba60b40-cf27-432f-8f37-df3b9f7b0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE :-  We perform clusters to get the labels (Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1393f8de-0434-4c6a-951e-a5622d7c2715",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c38eaa9-5882-4112-a237-606c61ac706f",
   "metadata": {},
   "source": [
    " Perform hierarchical clustering to identify the inherent groupings within your data. Then, plot the clusters.\n",
    " (use only 2 features. For example, try to cluster the customer base with respect to 'PURCHASES' and 'credit limit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7660a-f291-4522-b528-6dc9f3a9f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMEANS CLUSTERING ALGORITHMS \n",
    "from sklearn.cluster import KMeans,AgglomerativeClustering\n",
    "# Perform partitional clustering using the K-means algorithm. Then, plot the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025b6c7-e9b5-4514-82e1-1f66f063cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = AgglomerativeClustering(n_clusters=2,metric='euclidean')\n",
    "clusters.fit(data2[['PURCHASES','CREDIT_LIMIT']].iloc[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c91568-f93c-45df-bd4a-9aee6f27cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clusters.labels_[:100]\n",
    "np.unique(labels) # you realise that the model only generated 2 unique lables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f541e12-8da8-4648-a820-49271d7deaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = clusters.get_params()\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c048a2e-3ae0-4440-8658-ccc5813ffe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data2['PURCHASES'].iloc[:100], data2['CREDIT_LIMIT'].iloc[:100], c=labels[:100], cmap='viridis')\n",
    "# plt.scatter(data2['PAYMENTS'], data2['CREDIT_LIMIT'], c=labels, cmap='viridis')\n",
    "plt.title('Clusters of Purchases and Credit Limit (inheritance groups)')\n",
    "plt.xlabel('Purchases')\n",
    "plt.ylabel('Credit Limit')\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd10e96-64dd-491d-b999-a8431e0674dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc04d0-eace-4bb6-ace4-c5443cac1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform partitional clustering using the K-means algorithm. Then, plot the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56869c1-9305-49b4-8bc5-984160729d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_clusters = KMeans(n_clusters=2,random_state=100)\n",
    "kmeans_clusters.fit(data2[['PURCHASES','CREDIT_LIMIT']].iloc[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a556b-6ca5-4e26-bbea-fee046361ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans_clusters.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19647dcc-8789-4e8d-93f2-f6c33441821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE = []\n",
    "k_range = range(1,10)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k,random_state=100)\n",
    "    kmeans.fit(data2[['PURCHASES','CREDIT_LIMIT']].iloc[:100])\n",
    "    SSE.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068758d4-b5cc-4db9-b38a-5be0ff2ef661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow plot \n",
    "plt.plot(k_range,SSE,c='blue',marker='o')\n",
    "plt.xlabel(\"K values \")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.title(\"ELBOW PLOT\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5430dcb-d129-4d4e-9449-0139e2940517",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "# Plotting the first 100 points\n",
    "plt.scatter(data2['PURCHASES'][:100], data2['CREDIT_LIMIT'][:100], c=labels[:100], cmap='viridis', marker='o')\n",
    "plt.scatter(kmeans_clusters.cluster_centers_[:, 0], kmeans_clusters.cluster_centers_[:, 1], c='red', marker='x')  # Plotting centroids\n",
    "plt.title('K-Means Clustering of Purchases and Credit Limit (First 100 Points)')\n",
    "plt.xlabel('Purchases')\n",
    "plt.ylabel('Credit Limit')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8537e9bf-ae16-440f-8086-34c1cdcf07fb",
   "metadata": {},
   "source": [
    "# Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bea540-1f13-47ae-a87e-94d0ee94205c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740a6373-3de6-4e38-b8cf-da23484bb749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the algorithms above Hirrachial model is better in this case because we dont know the number of clusters that we have\n",
    "# in this case despite both of the having the same output \n",
    "# 2. the model shows that the best labels we have is 0 and 1 we can only establish to clusters from the samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091d4c6e-6404-4302-961a-46ae9e92a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model algorithm\n",
    "'''\n",
    "from the dataset the first input was :\n",
    "  CUST_ID\t    BALANCE_FREQUENCY\tPURCHASES\tPAYMENTS\tCREDIT_LIMIT\tCASH_ADVANCE\n",
    "0    C10001\t    0.818182\t        95.40\t     201.802084\t  1000.0\t     0.000000 \n",
    "1\t C10002  \t0.909091\t        0.00\t    4103.032597\t  7000.0\t     6442.945483\n",
    "6934 C17123\t    1.000000\t        0.00\t    263.793622\t  1200.0\t     119.746155\n",
    "'''\n",
    "\n",
    "# according to this we want to predict the customer label of this customer will be ? basing on the PURCHASES COLUMN AND CREDIT_LIMIT\n",
    "print(f\"the first {kmeans_clusters.predict([[95,1000]])}\") # 1st\n",
    "print(f\"the 2nd client {kmeans_clusters.predict([[95,1000]])}\") # second\n",
    "print(kmeans_clusters.predict([[0,1200]]) )# the customer 6934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5831540-77a9-4de6-9cb4-a6404dca028b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d6b8b9-6c7d-4f4c-bf64-46425c2e2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the customers we can classify him as cluster 0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
